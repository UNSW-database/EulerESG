"""
å®Œæ•´çš„ESGåˆ†æå·¥ä½œæµç¤ºä¾‹
åŒ…å«æ‰€æœ‰5ä¸ªæ¨¡å—çš„é›†æˆä½¿ç”¨
"""

import os
from pathlib import Path
from src.esg_encoding import (
    ProcessingConfig,
    ReportEncoder,
    MetricProcessor,
    DualChannelRetriever,
    DisclosureInferenceEngine,
    ESGChatbot,
    ChatRequest
)
from loguru import logger

# é…ç½®æ—¥å¿—
logger.add("esg_complete_workflow.log", rotation="10 MB")


def run_complete_esg_workflow(
    pdf_path: str,
    metrics_excel_path: str = None,
    llm_api_key: str = None,
    llm_base_url: str = None
):
    """
    è¿è¡Œå®Œæ•´çš„ESGåˆ†æå·¥ä½œæµ
    
    Args:
        pdf_path: ESGæŠ¥å‘ŠPDFæ–‡ä»¶è·¯å¾„
        metrics_excel_path: æŒ‡æ ‡Excelæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰
        llm_api_key: LLM APIå¯†é’¥ï¼ˆå¯é€‰ï¼‰
        llm_base_url: LLM APIåŸºç¡€URLï¼ˆå¯é€‰ï¼‰
        
    Returns:
        tuple: (åˆè§„è¯„ä¼°ç»“æœ, èŠå¤©æœºå™¨äººå®ä¾‹)
    """
    
    logger.info("=" * 80)
    logger.info("å¼€å§‹å®Œæ•´çš„ESGåˆ†æå·¥ä½œæµ")
    logger.info("=" * 80)
    
    # ========== æ­¥éª¤1: åˆå§‹åŒ–é…ç½® ==========
    logger.info("\næ­¥éª¤1: åˆå§‹åŒ–ç³»ç»Ÿé…ç½®")
    config = ProcessingConfig(
        embedding_model="BAAI/bge-m3",
        device="cpu",  # æˆ– "cuda" å¦‚æœæœ‰GPU
        batch_size=16,
        max_length=512,
        top_k=10,
        similarity_threshold=0.3,
        llm_api_key=llm_api_key,
        llm_model="gpt-3.5-turbo",
        llm_base_url=llm_base_url
    )
    
    # åˆå§‹åŒ–å„æ¨¡å—
    report_encoder = ReportEncoder(config)
    metric_processor = MetricProcessor(config)
    dual_retriever = DualChannelRetriever(config)
    disclosure_engine = DisclosureInferenceEngine(config)
    chatbot = ESGChatbot(config)
    
    logger.info("âœ… ç³»ç»Ÿç»„ä»¶åˆå§‹åŒ–å®Œæˆ")
    
    # ========== æ­¥éª¤2: å¤„ç†ESGæŠ¥å‘Š ==========
    logger.info("\næ­¥éª¤2: å¤„ç†ESGæŠ¥å‘Š")
    logger.info(f"æŠ¥å‘Šæ–‡ä»¶: {pdf_path}")
    
    # ç¼–ç PDFæŠ¥å‘Š
    report_content = report_encoder.encode_pdf(pdf_path, save_markdown=True)
    
    # è·å–æŠ¥å‘Šæ‘˜è¦
    summary = report_encoder.get_report_summary(report_content)
    logger.info(f"âœ… æŠ¥å‘Šå¤„ç†å®Œæˆ")
    logger.info(f"   - æ–‡æ¡£ID: {report_content.document_id}")
    logger.info(f"   - æ€»æ®µè½æ•°: {summary['total_segments']}")
    logger.info(f"   - æ€»é¡µæ•°: {summary['total_pages']}")
    
    # ========== æ­¥éª¤3: åŠ è½½å’Œå¤„ç†ESGæŒ‡æ ‡ ==========
    logger.info("\næ­¥éª¤3: åŠ è½½å’Œå¤„ç†ESGæŒ‡æ ‡")
    
    if metrics_excel_path and Path(metrics_excel_path).exists():
        # ä»ExcelåŠ è½½æŒ‡æ ‡
        logger.info(f"ä»ExcelåŠ è½½æŒ‡æ ‡: {metrics_excel_path}")
        metric_collection = metric_processor.load_metrics_from_excel(metrics_excel_path)
    else:
        # ä½¿ç”¨ç¤ºä¾‹æŒ‡æ ‡
        logger.info("ä½¿ç”¨ç¤ºä¾‹ESGæŒ‡æ ‡")
        metric_collection = metric_processor.create_sample_metrics()
    
    logger.info(f"åŠ è½½äº† {len(metric_collection.metrics)} ä¸ªæŒ‡æ ‡")
    
    # å¤„ç†æŒ‡æ ‡ï¼ˆè¯­ä¹‰æ‰©å±•ï¼‰
    if config.llm_api_key:
        logger.info("æ‰§è¡ŒæŒ‡æ ‡è¯­ä¹‰æ‰©å±•...")
        processed_collection = metric_processor.process_metric_collection(metric_collection)
        logger.info("âœ… è¯­ä¹‰æ‰©å±•å®Œæˆ")
    else:
        processed_collection = metric_collection
        logger.warning("âš ï¸ æœªé…ç½®LLM APIï¼Œè·³è¿‡è¯­ä¹‰æ‰©å±•")
    
    # ä¿å­˜å¤„ç†åçš„æŒ‡æ ‡
    output_path = Path("outputs") / f"processed_metrics_{report_content.document_id}.json"
    output_path.parent.mkdir(exist_ok=True)
    metric_processor.save_metrics_to_file(processed_collection, str(output_path))
    logger.info(f"âœ… æŒ‡æ ‡ä¿å­˜åˆ°: {output_path}")
    
    # ========== æ­¥éª¤4: åŒé€šé“æ£€ç´¢ ==========
    logger.info("\næ­¥éª¤4: æ‰§è¡ŒåŒé€šé“æ£€ç´¢")
    
    retrieval_results = dual_retriever.retrieve_for_collection(
        report_content,
        processed_collection
    )
    
    logger.info(f"âœ… æ£€ç´¢å®Œæˆï¼Œå¤„ç†äº† {len(retrieval_results)} ä¸ªæŒ‡æ ‡")
    
    # ç”Ÿæˆæ£€ç´¢æŠ¥å‘Š
    retrieval_report = dual_retriever.generate_retrieval_report(retrieval_results)
    report_path = Path("outputs") / f"retrieval_report_{report_content.document_id}.md"
    with open(report_path, "w", encoding="utf-8") as f:
        f.write(retrieval_report)
    logger.info(f"   æ£€ç´¢æŠ¥å‘Šä¿å­˜åˆ°: {report_path}")
    
    # ========== æ­¥éª¤5: æŠ«éœ²åˆè§„åˆ†æ ==========
    logger.info("\næ­¥éª¤5: æ‰§è¡ŒæŠ«éœ²åˆè§„åˆ†æ")
    
    compliance_assessment = disclosure_engine.analyze_compliance(
        retrieval_results,
        report_content,
        pdf_path
    )
    
    logger.info(f"âœ… åˆè§„åˆ†æå®Œæˆ")
    logger.info(f"   - æ•´ä½“åˆè§„åˆ†æ•°: {compliance_assessment.overall_compliance_score:.2%}")
    logger.info(f"   - å®Œå…¨æŠ«éœ²: {compliance_assessment.disclosure_summary.get('fully_disclosed', 0)} ä¸ª")
    logger.info(f"   - éƒ¨åˆ†æŠ«éœ²: {compliance_assessment.disclosure_summary.get('partially_disclosed', 0)} ä¸ª")
    logger.info(f"   - æœªæŠ«éœ²: {compliance_assessment.disclosure_summary.get('not_disclosed', 0)} ä¸ª")
    
    # ç”Ÿæˆåˆè§„æŠ¥å‘Š
    compliance_report = disclosure_engine.generate_compliance_report(compliance_assessment)
    report_path = Path("outputs") / f"compliance_report_{report_content.document_id}.md"
    with open(report_path, "w", encoding="utf-8") as f:
        f.write(compliance_report)
    logger.info(f"   åˆè§„æŠ¥å‘Šä¿å­˜åˆ°: {report_path}")
    
    # ========== æ­¥éª¤6: åˆå§‹åŒ–èŠå¤©æœºå™¨äºº ==========
    logger.info("\næ­¥éª¤6: åˆå§‹åŒ–ESGèŠå¤©æœºå™¨äºº")
    
    # åŠ è½½ä¸Šä¸‹æ–‡åˆ°èŠå¤©æœºå™¨äºº
    chatbot.load_context(report_content, compliance_assessment)
    
    # åˆ›å»ºä¼šè¯
    session_id = chatbot.create_session()
    logger.info(f"âœ… èŠå¤©æœºå™¨äººå°±ç»ªï¼Œä¼šè¯ID: {session_id}")
    
    # ========== æ­¥éª¤7: æ¼”ç¤ºèŠå¤©åŠŸèƒ½ ==========
    logger.info("\næ­¥éª¤7: æ¼”ç¤ºèŠå¤©åŠŸèƒ½")
    
    # ç¤ºä¾‹é—®é¢˜
    demo_questions = [
        "è¿™ä»½æŠ¥å‘Šçš„æ•´ä½“ESGåˆè§„æƒ…å†µå¦‚ä½•ï¼Ÿ",
        "å“ªäº›æŒ‡æ ‡è¿˜æ²¡æœ‰å……åˆ†æŠ«éœ²ï¼Ÿ",
        "è¯·è§£é‡Šä¸€ä¸‹ä»€ä¹ˆæ˜¯ç¢³æ’æ”¾æŒ‡æ ‡ï¼Ÿ",
        "æŠ¥å‘Šä¸­æœ‰å…³ç¯å¢ƒä¿æŠ¤çš„ä¸»è¦æªæ–½æ˜¯ä»€ä¹ˆï¼Ÿ"
    ]
    
    for i, question in enumerate(demo_questions[:2], 1):  # æ¼”ç¤ºå‰2ä¸ªé—®é¢˜
        logger.info(f"\né—®é¢˜{i}: {question}")
        
        request = ChatRequest(
            session_id=session_id,
            message=question,
            include_context=True
        )
        
        response = chatbot.chat(request)
        logger.info(f"å›ç­” (ç½®ä¿¡åº¦: {response.confidence:.2f}): {response.response[:200]}...")
        
        if response.relevant_segments:
            logger.info(f"ç›¸å…³æ®µè½: {', '.join(response.relevant_segments)}")
    
    # ========== å®Œæˆ ==========
    logger.info("\n" + "=" * 80)
    logger.info("âœ… å®Œæ•´çš„ESGåˆ†æå·¥ä½œæµæ‰§è¡Œå®Œæˆï¼")
    logger.info("=" * 80)
    
    # è¾“å‡ºæ€»ç»“
    logger.info("\nğŸ“Š åˆ†ææ€»ç»“:")
    logger.info(f"1. æŠ¥å‘ŠåŒ…å« {summary['total_segments']} ä¸ªæ®µè½ï¼Œ{summary['total_pages']} é¡µ")
    logger.info(f"2. åˆ†æäº† {len(processed_collection.metrics)} ä¸ªESGæŒ‡æ ‡")
    logger.info(f"3. æ•´ä½“åˆè§„åˆ†æ•°: {compliance_assessment.overall_compliance_score:.2%}")
    logger.info(f"4. èŠå¤©æœºå™¨äººå·²å°±ç»ªï¼Œå¯é€šè¿‡APIè¿›è¡Œäº¤äº’")
    
    logger.info("\nğŸ“ ç”Ÿæˆçš„æ–‡ä»¶:")
    logger.info(f"- MarkdownæŠ¥å‘Š: {pdf_path.replace('.pdf', '_extracted.md')}")
    logger.info(f"- å¤„ç†åçš„æŒ‡æ ‡: outputs/processed_metrics_{report_content.document_id}.json")
    logger.info(f"- æ£€ç´¢æŠ¥å‘Š: outputs/retrieval_report_{report_content.document_id}.md")
    logger.info(f"- åˆè§„æŠ¥å‘Š: outputs/compliance_report_{report_content.document_id}.md")
    
    return compliance_assessment, chatbot


def interactive_chat_demo(chatbot: ESGChatbot, session_id: str = None):
    """
    äº¤äº’å¼èŠå¤©æ¼”ç¤º
    
    Args:
        chatbot: ESGèŠå¤©æœºå™¨äººå®ä¾‹
        session_id: ä¼šè¯IDï¼ˆå¯é€‰ï¼‰
    """
    if not session_id:
        session_id = chatbot.create_session()
    
    print("\n" + "=" * 60)
    print("ESGæ™ºèƒ½é—®ç­”ç³»ç»Ÿ")
    print("=" * 60)
    print("è¾“å…¥æ‚¨çš„é—®é¢˜ï¼Œæˆ–è¾“å…¥ 'quit' é€€å‡º")
    print("-" * 60)
    
    while True:
        # è·å–ç”¨æˆ·è¾“å…¥
        user_input = input("\næ‚¨çš„é—®é¢˜: ").strip()
        
        if user_input.lower() in ['quit', 'exit', 'q']:
            print("æ„Ÿè°¢ä½¿ç”¨ï¼Œå†è§ï¼")
            break
        
        if not user_input:
            continue
        
        # å‘é€è¯·æ±‚
        request = ChatRequest(
            session_id=session_id,
            message=user_input,
            include_context=True
        )
        
        # è·å–å›å¤
        response = chatbot.chat(request)
        
        # æ˜¾ç¤ºå›å¤
        print(f"\næœºå™¨äººå›å¤ (ç½®ä¿¡åº¦: {response.confidence:.2f}):")
        print("-" * 60)
        print(response.response)
        
        if response.relevant_segments:
            print(f"\nå‚è€ƒæ®µè½: {', '.join(response.relevant_segments[:3])}")


if __name__ == "__main__":
    # é…ç½®å‚æ•°
    PDF_PATH = "dell (1).pdf"  # æ›¿æ¢ä¸ºæ‚¨çš„PDFæ–‡ä»¶è·¯å¾„
    EXCEL_PATH = "demo data - updated(1).xlsx"  # å¯é€‰ï¼šExcelæŒ‡æ ‡æ–‡ä»¶
    
    # LLMé…ç½®ï¼ˆå¯é€‰ï¼‰
    # å¦‚æœæ²¡æœ‰é…ç½®ï¼Œç³»ç»Ÿå°†ä½¿ç”¨åŸºäºè§„åˆ™çš„åˆ†æ
    LLM_API_KEY = os.getenv("LLM_API_KEY", None)
    LLM_BASE_URL = os.getenv("LLM_BASE_URL", None)
    
    # æ£€æŸ¥æ–‡ä»¶
    if not Path(PDF_PATH).exists():
        logger.error(f"PDFæ–‡ä»¶ä¸å­˜åœ¨: {PDF_PATH}")
        exit(1)
    
    try:
        # è¿è¡Œå®Œæ•´å·¥ä½œæµ
        assessment, chatbot = run_complete_esg_workflow(
            pdf_path=PDF_PATH,
            metrics_excel_path=EXCEL_PATH,
            llm_api_key=LLM_API_KEY,
            llm_base_url=LLM_BASE_URL
        )
        
        # å¯é€‰ï¼šå¯åŠ¨äº¤äº’å¼èŠå¤©
        print("\næ˜¯å¦å¯åŠ¨äº¤äº’å¼èŠå¤©ï¼Ÿ(y/n): ", end="")
        if input().lower() == 'y':
            interactive_chat_demo(chatbot)
        
    except Exception as e:
        logger.error(f"å·¥ä½œæµæ‰§è¡Œå¤±è´¥: {e}")
        raise